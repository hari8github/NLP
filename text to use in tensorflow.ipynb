{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1a0ab3-f5a7-4cd3-a187-fc5a644f586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcabbf77-6ad4-4d56-b99e-8dfea043e290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stars twinkle brightly in the night sky.', 'Space travel fascinates many people.', 'The moon orbits around Earth.', 'Astronauts float in zero gravity.', 'Telescopes reveal distant galaxies.', 'Planets revolve around the sun.']\n"
     ]
    }
   ],
   "source": [
    "sentences = ['Stars twinkle brightly in the night sky.',\n",
    "'Space travel fascinates many people.',\n",
    "'The moon orbits around Earth.',\n",
    "'Astronauts float in zero gravity.',\n",
    "'Telescopes reveal distant galaxies.',\n",
    "'Planets revolve around the sun.']\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9d91b6-5a33-4864-8f0f-ab712cf9aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 100, oov_token = '<OOV>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efdee50a-1ab8-4361-9796-764df1d1a6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'the': 2, 'in': 3, 'around': 4, 'stars': 5, 'twinkle': 6, 'brightly': 7, 'night': 8, 'sky': 9, 'space': 10, 'travel': 11, 'fascinates': 12, 'many': 13, 'people': 14, 'moon': 15, 'orbits': 16, 'earth': 17, 'astronauts': 18, 'float': 19, 'zero': 20, 'gravity': 21, 'telescopes': 22, 'reveal': 23, 'distant': 24, 'galaxies': 25, 'planets': 26, 'revolve': 27, 'sun': 28}\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62d670a-05a2-4615-9ef9-2e0ab24c5be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 6, 7, 3, 2, 8, 9], [10, 11, 12, 13, 14], [2, 15, 16, 4, 17], [18, 19, 3, 20, 21], [22, 23, 24, 25], [26, 27, 4, 2, 28]]\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a83b5b-bf12-4dc1-b6c3-2864f64fe6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Sequences:  [[ 5  6  7  3  2  8  9]\n",
      " [ 0  0 10 11 12 13 14]\n",
      " [ 0  0  2 15 16  4 17]\n",
      " [ 0  0 18 19  3 20 21]\n",
      " [ 0  0  0 22 23 24 25]\n",
      " [ 0  0 26 27  4  2 28]]\n"
     ]
    }
   ],
   "source": [
    "padded = pad_sequences(sequences)\n",
    "print(\"Padded Sequences: \", padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b303dfb2-c980-4bf1-bc84-e5a83ff28a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  5  6  7  3  2  8  9]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 10 11 12 13 14]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2 15 16  4 17]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18 19  3 20 21]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 22 23 24 25]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 26 27  4  2 28]]\n"
     ]
    }
   ],
   "source": [
    "padded = pad_sequences(sequences, maxlen = 15)\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee126d3-b2e7-4506-922e-0c8c92672d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  6  7  3  2  8  9  0  0  0  0  0  0  0  0]\n",
      " [10 11 12 13 14  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 15 16  4 17  0  0  0  0  0  0  0  0  0  0]\n",
      " [18 19  3 20 21  0  0  0  0  0  0  0  0  0  0]\n",
      " [22 23 24 25  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [26 27  4  2 28  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "padded = pad_sequences(sequences, maxlen = 15, padding = 'post')\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "807c2b72-52c2-45ff-8e4b-7014500a69b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  8  9]\n",
      " [12 13 14]\n",
      " [16  4 17]\n",
      " [ 3 20 21]\n",
      " [23 24 25]\n",
      " [ 4  2 28]]\n"
     ]
    }
   ],
   "source": [
    "padded = pad_sequences(sequences, maxlen = 3)\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1edf75d-7496-42c6-8bdc-346c0adc2e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Comets leave shimmering trails in the cosmos.', 'Nebulae are stellar nurseries in space.']\n"
     ]
    }
   ],
   "source": [
    "test_data = ['Comets leave shimmering trails in the cosmos.',\n",
    "'Nebulae are stellar nurseries in space.']\n",
    "\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b8f8a67-93cb-44c8-a465-e26101795809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OOV> has the number 1 in the word index.\n"
     ]
    }
   ],
   "source": [
    "print(\"<OOV> has the number\", word_index['<OOV>'], \"in the word index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5738947-a461-4f53-8df9-a85f296d1cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sequences:  [[1, 1, 1, 1, 3, 2, 1], [1, 1, 1, 1, 3, 10]]\n"
     ]
    }
   ],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(test_data)\n",
    "print(\"Test sequences: \", test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd84e56f-a439-46e9-b533-9f79b4e2d4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  1  1  1  1  3  2  1]\n",
      " [ 0  0  0  0  1  1  1  1  3 10]]\n"
     ]
    }
   ],
   "source": [
    "padded = pad_sequences(test_seq, maxlen = 10)\n",
    "print(padded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
